{
    "name": "Scala",
    "build": {
        "dockerfile": "Dockerfile"
    },
    // NOTE: we make hostname consistent to not have to resolve random generated 
    //       container hostname when connecting to the standalone Spark cluster
    "runArgs": [
        "--name",
        "${localWorkspaceFolderBasename}",
        "--hostname",
        "${localWorkspaceFolderBasename}"
    ],
    "mounts": [
        // Persist /var/spark-events between container restarts
        {
            "source": "${localWorkspaceFolderBasename}-spark-events",
            "target": "/var/spark-events",
            "type": "volume"
        },
        // persist coursier cache between container restarts
        {
            "source": "${localWorkspaceFolderBasename}-coursier-cache",
            "target": "/home/ubuntu/.cache/coursier",
            "type": "volume"
        }
    ],
    // Use root to run postCreateCommand chown, then switch to 'ubuntu' user
    "containerUser": "root",
    "remoteUser": "ubuntu",
    // NOTE: running as root user (see containerUser), so no sudo needed
    "postCreateCommand": {
        // Link the custom spark-defaults.conf into SPARK_HOME/conf
        "linkSparkConfig": "ln -s ${containerWorkspaceFolder}/spark-defaults.conf ${containerEnv:SPARK_HOME}/conf/spark-defaults.conf",
        "linkSparkEnv": "ln -s ${containerWorkspaceFolder}/spark-env.sh ${containerEnv:SPARK_HOME}/conf/spark-env.sh",
        // NOTE: this command was supposed to be executed by ubuntu user, but we only have root to run commands at container creation, so we run it as root and chown it
        "linkJupyterConfig": "mkdir -p /home/ubuntu/.jupyter && ln -s ${containerWorkspaceFolder}/jupyter_server_config.json /home/ubuntu/.jupyter/jupyter_server_config.json && chown -R ubuntu:ubuntu /home/ubuntu/.jupyter",
        // Mounting a volume sets root as owner, so we need to chown it to ubuntu
        // NOTE: running as root user (see containerUser), so no sudo needed
        "chownSparkEvents": "chown -R ubuntu:ubuntu /var/spark-events",
        "createPythonEnv": "bash -lc 'python3 -m venv ${containerWorkspaceFolder}/.venv && source ${containerWorkspaceFolder}/.venv/bin/activate && pip install --upgrade pip && pip install -r ${containerWorkspaceFolder}/requirements.txt'"
    },
    // runs as remoteUser 'ubuntu'
    "postStartCommand": {
        "startSpark": "${containerWorkspaceFolder}/scripts/start-spark.sh",
        // NOTE: we redirect to /dev/null to prevent nohup from streaming the output to ./nohup.out
        // NOTE: -l is used to load pipx packages paths from .bashrc, added when ran `pipx ensurepath`
        "startJupyter": "nohup bash -lc 'jupyter lab --no-browser --ip=127.0.0.1 --port=8888 > .jupyter.log 2>&1 &' > /dev/null"
    },
    // NOTE: More ports will be forwarded by VSCode automatically, but those are the main ones used by scripts in ./scripts/
    "forwardPorts": [
        8080,  // Spark Master Web UI
        8081,  // Spark Worker 1 Web UI
        8082,  // Spark Worker 2 Web UI
        8083,  // Spark Worker 3 Web UI
        18080, // Spark History Server Web UI
        4040,  // Spark Application Web UI
        8888   // Jupyter Notebook
    ],
    // NOTE: JAVA_TOOL_OPTIONS is used to avoid almond kernel issues with Spark 3.3.X & Java 17+
    //       See: https://stackoverflow.com/questions/73465937/apache-spark-3-3-0-breaks-on-java-17-with-cannot-access-class-sun-nio-ch-direct
    "remoteEnv": {
        "PATH": "${containerEnv:SPARK_HOME}/bin:${containerEnv:SPARK_HOME}/sbin:${containerEnv:PATH}",
        "JAVA_TOOL_OPTIONS": "--add-exports=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED"
    },
    "containerEnv": {
        "JAVA_TOOL_OPTIONS": "--add-exports=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED"
    },
    "customizations": {
        "vscode": {
            "settings": {
                "terminal.integrated.defaultProfile.linux": "bash"
            },
            "extensions": [
                "streetsidesoftware.code-spell-checker",
                "berublan.vscode-log-viewer",
                "mechatroner.rainbow-csv",
                "mads-hartmann.bash-ide-vscode",
                "scala-lang.scala",
                "scalameta.metals",
                "ms-toolsai.jupyter",
                "christian-kohler.path-intellisense",
                "tintinweb.graphviz-interactive-preview",
                "ms-python.python"
            ]
        }
    }
}